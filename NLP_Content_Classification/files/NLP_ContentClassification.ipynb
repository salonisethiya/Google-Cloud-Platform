{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import argparse\n",
    "import io\n",
    "import json\n",
    "from google.cloud import language\n",
    "import numpy\n",
    "import six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting path to json key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/affine/GCP/downloaded_key.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Content classification:**\n",
    "\n",
    "- Content Classification analyzes a document and returns a list of content categories that apply to the text found in the document.\n",
    "\n",
    "- To use the Cloud Natural Language API, you must to import the language module from the google-cloud-language library. \n",
    "\n",
    "- The language.types module contains classes that are required for creating requests.\n",
    "\n",
    "- The language.enums module is used to specify the type of the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Classifying content provided a string : first method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use the Python client library to make a request to the Natural Language to classify content. The Python client library encapsulates the details for requests to and responses from the Natural Language.\n",
    "\n",
    "\n",
    "- The below function calls the Natural Language 'classifyText' method, by first creating an instance of the LanguageServiceClient class, and then calling the classify_text method of the LanguageServiceClient instance.\n",
    "\n",
    "\n",
    "- The below function only classifies text content. You can also classify the content of a web page by passing in the source HTML of the web page as the text and by setting the type parameter to language.enums.Document.Type.HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify a ‘text string’ passed by the user\n",
    "\n",
    "def sample_classify_text(text_content):\n",
    "    \"\"\"\n",
    "    Classifying Content in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze. Must include at least 20 words.\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    response = client.classify_text(document)\n",
    "    print('response:\\n ',response)\n",
    "    # Loop through classified categories returned from the API\n",
    "    for category in response.categories:\n",
    "        # Get the name of the category representing the document.\n",
    "        # See the predefined taxonomy of categories:\n",
    "        # https://cloud.google.com/natural-language/docs/categories\n",
    "        print(u\"Category name: {}\".format(category.name))\n",
    "        # Get the confidence. Number representing how certain the classifier\n",
    "        # is that this category represents the provided text.\n",
    "        print(u\"Confidence: {}\".format(category.confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "  categories {\n",
      "  name: \"/Sports/Individual Sports/Golf\"\n",
      "  confidence: 0.9900000095367432\n",
      "}\n",
      "\n",
      "Category name: /Sports/Individual Sports/Golf\n",
      "Confidence: 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "# calling function:\n",
    "\n",
    "sample_classify_text('Golf is a club-and-ball sport in which players use various clubs to hit balls into a series of holes on a course in as few strokes as possible.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "  categories {\n",
      "  name: \"/Computers & Electronics/Software\"\n",
      "  confidence: 0.550000011920929\n",
      "}\n",
      "categories {\n",
      "  name: \"/Internet & Telecom\"\n",
      "  confidence: 0.5099999904632568\n",
      "}\n",
      "\n",
      "Category name: /Computers & Electronics/Software\n",
      "Confidence: 0.550000011920929\n",
      "Category name: /Internet & Telecom\n",
      "Confidence: 0.5099999904632568\n"
     ]
    }
   ],
   "source": [
    "# example:\n",
    "\n",
    "sample_classify_text(\"Google Home enables users to speak voice commands to interact with services through the Home's intelligent personal assistant called Google Assistant. A large number of services, both in-house and third-party, are integrated, allowing users to listen to music, look at videos or photos, or receive news updates entirely by voice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "Response gives categories to which given text string belongs to from list of content categories returned for the **classifyText** method.\n",
    "\n",
    "In categories it gives:\n",
    "\n",
    "name: name of the category\n",
    "\n",
    "confidence : confidence score\n",
    "\n",
    "The given text can belong to more than one category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Classify content provided a string: second method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, verbose=True):\n",
    "    \"\"\"Classify the input text into categories. \"\"\"\n",
    "\n",
    "    language_client = language.LanguageServiceClient()\n",
    "\n",
    "    document = language.types.Document(\n",
    "        content=text,\n",
    "        type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "    response = language_client.classify_text(document)\n",
    "    print('response: \\n',response)\n",
    "    categories = response.categories\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for category in categories:\n",
    "        # Turn the categories into a dictionary of the form:\n",
    "        # {category.name: category.confidence}, so that they can\n",
    "        # be treated as a sparse vector.\n",
    "        result[category.name] = category.confidence\n",
    "\n",
    "    if verbose:\n",
    "        print(text)\n",
    "        for category in categories:\n",
    "            print(u'=' * 20)\n",
    "            print(u'{:<16}: {}'.format('category', category.name))\n",
    "            print(u'{:<16}: {}'.format('confidence', category.confidence))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: \n",
      " categories {\n",
      "  name: \"/Computers & Electronics/Software\"\n",
      "  confidence: 0.550000011920929\n",
      "}\n",
      "categories {\n",
      "  name: \"/Internet & Telecom\"\n",
      "  confidence: 0.5099999904632568\n",
      "}\n",
      "\n",
      "Google Home enables users to speak voice commands to interact with services through the Home's intelligent personal assistant called Google Assistant. A large number of services, both in-house and third-party, are integrated, allowing users to listen to music, look at videos or photos, or receive news updates entirely by voice.\n",
      "====================\n",
      "category        : /Computers & Electronics/Software\n",
      "confidence      : 0.550000011920929\n",
      "====================\n",
      "category        : /Internet & Telecom\n",
      "confidence      : 0.5099999904632568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'/Computers & Electronics/Software': 0.550000011920929,\n",
       " '/Internet & Telecom': 0.5099999904632568}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling function\n",
    "\n",
    "classify(\"Google Home enables users to speak voice commands to interact with services through the Home's intelligent personal assistant called Google Assistant. A large number of services, both in-house and third-party, are integrated, allowing users to listen to music, look at videos or photos, or receive news updates entirely by voice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "The returned result is a dictionary with the category labels as keys, and confidence scores as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Classifying Content from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_classify_text_uri(gcs_content_uri):\n",
    "    \"\"\"\n",
    "    Classifying Content in text file stored in Cloud Storage\n",
    "\n",
    "    Args:\n",
    "      gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
    "      e.g. gs://[Your Bucket]/[Path to File]\n",
    "      The text file must include at least 20 words.\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"gcs_content_uri\": gcs_content_uri, \"type\": type_, \"language\": language}\n",
    "\n",
    "    response = client.classify_text(document)\n",
    "    print('response: \\n',response)\n",
    "    result = {}\n",
    "    # Loop through classified categories returned from the API\n",
    "    for category in response.categories:\n",
    "        # Get the name of the category representing the document.\n",
    "        # See the predefined taxonomy of categories:\n",
    "        # https://cloud.google.com/natural-language/docs/categories\n",
    "        print(u\"Category name: {}\".format(category.name))\n",
    "        # Get the confidence. Number representing how certain the classifier\n",
    "        # is that this category represents the provided text.\n",
    "        print(u\"Confidence: {}\".format(category.confidence))\n",
    "        \n",
    "        # Turn the categories into a dictionary of the form:\n",
    "        # {category.name: category.confidence}, so that they can\n",
    "        # be treated as a sparse vector.\n",
    "        result[category.name] = category.confidence\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Classifying content stored in a text file on Google Cloud Storage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text in txt file uri:\n",
    "\n",
    "Your food choices each day affect your health — how you feel today, tomorrow, and in the future. Good nutrition is an important part of leading a healthy lifestyle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: \n",
      " categories {\n",
      "  name: \"/Health/Nutrition\"\n",
      "  confidence: 0.7799999713897705\n",
      "}\n",
      "categories {\n",
      "  name: \"/Food & Drink\"\n",
      "  confidence: 0.5400000214576721\n",
      "}\n",
      "\n",
      "Category name: /Health/Nutrition\n",
      "Confidence: 0.7799999713897705\n",
      "Category name: /Food & Drink\n",
      "Confidence: 0.5400000214576721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'/Health/Nutrition': 0.7799999713897705, '/Food & Drink': 0.5400000214576721}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling function by giving txt file uri\n",
    "\n",
    "sample_classify_text_uri(\"gs://bucket0406/string1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see input text belongs to two categories and confidence score of text beloning to first category is more as compared to second one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Classifying content stored in a pdf file on Google Cloud Storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: \n",
      " categories {\n",
      "  name: \"/Computers & Electronics/Software\"\n",
      "  confidence: 0.7099999785423279\n",
      "}\n",
      "\n",
      "Category name: /Computers & Electronics/Software\n",
      "Confidence: 0.7099999785423279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'/Computers & Electronics/Software': 0.7099999785423279}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling function by giving pdf file uri\n",
    "\n",
    "sample_classify_text_uri(\"gs://bucket0406/text.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Index multiple text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classify multiple text files and write the result to an index file.\n",
    "\n",
    "\n",
    "- The below index function takes, as input, a directory containing multiple text files, and the path to a file where it stores the indexed output (the default file name is index.json). \n",
    "\n",
    "\n",
    "- It reads the content of each text file in the input directory, and then passes the text files to the Cloud Natural Language API to be classified into content categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(path, index_file):\n",
    "    \"\"\"Classify each text file in a directory and write\n",
    "    the results to the index_file.\n",
    "    \"\"\"\n",
    "\n",
    "    results = {}\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with io.open(file_path, 'r') as f:\n",
    "                text = f.read()\n",
    "                print('for file: ', filename)\n",
    "                categories = classify(text, verbose=False)\n",
    "                \n",
    "\n",
    "                results[filename] = categories\n",
    "        except Exception:\n",
    "            print('Failed to process {}'.format(file_path))\n",
    "\n",
    "    with io.open(index_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(results, ensure_ascii=False))\n",
    "\n",
    "    print('Texts indexed in file: {}'.format(index_file))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for file:  string1.txt\n",
      "response: \n",
      " categories {\n",
      "  name: \"/Health/Nutrition\"\n",
      "  confidence: 0.7799999713897705\n",
      "}\n",
      "categories {\n",
      "  name: \"/Food & Drink\"\n",
      "  confidence: 0.5400000214576721\n",
      "}\n",
      "\n",
      "for file:  string5.txt\n",
      "response: \n",
      " categories {\n",
      "  name: \"/Books & Literature/Children\\'s Literature\"\n",
      "  confidence: 0.9900000095367432\n",
      "}\n",
      "categories {\n",
      "  name: \"/People & Society/Kids & Teens/Children\\'s Interests\"\n",
      "  confidence: 0.9700000286102295\n",
      "}\n",
      "\n",
      "for file:  string4.txt\n",
      "response: \n",
      " categories {\n",
      "  name: \"/Books & Literature/Children\\'s Literature\"\n",
      "  confidence: 0.9200000166893005\n",
      "}\n",
      "categories {\n",
      "  name: \"/People & Society/Kids & Teens/Children\\'s Interests\"\n",
      "  confidence: 0.8100000023841858\n",
      "}\n",
      "\n",
      "for file:  string6.txt\n",
      "response: \n",
      " categories {\n",
      "  name: \"/Books & Literature/Children\\'s Literature\"\n",
      "  confidence: 0.9200000166893005\n",
      "}\n",
      "categories {\n",
      "  name: \"/People & Society/Kids & Teens/Children\\'s Interests\"\n",
      "  confidence: 0.8500000238418579\n",
      "}\n",
      "categories {\n",
      "  name: \"/People & Society/Subcultures & Niche Interests\"\n",
      "  confidence: 0.5600000023841858\n",
      "}\n",
      "\n",
      "for file:  string3.txt\n",
      "response: \n",
      " categories {\n",
      "  name: \"/Internet & Telecom/Mobile & Wireless\"\n",
      "  confidence: 0.6299999952316284\n",
      "}\n",
      "categories {\n",
      "  name: \"/Internet & Telecom/Service Providers\"\n",
      "  confidence: 0.5199999809265137\n",
      "}\n",
      "\n",
      "for file:  string2.txt\n",
      "response: \n",
      " categories {\n",
      "  name: \"/Internet & Telecom\"\n",
      "  confidence: 0.7099999785423279\n",
      "}\n",
      "\n",
      "Texts indexed in file: index.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'string1.txt': {'/Health/Nutrition': 0.7799999713897705,\n",
       "  '/Food & Drink': 0.5400000214576721},\n",
       " 'string5.txt': {\"/Books & Literature/Children's Literature\": 0.9900000095367432,\n",
       "  \"/People & Society/Kids & Teens/Children's Interests\": 0.9700000286102295},\n",
       " 'string4.txt': {\"/Books & Literature/Children's Literature\": 0.9200000166893005,\n",
       "  \"/People & Society/Kids & Teens/Children's Interests\": 0.8100000023841858},\n",
       " 'string6.txt': {\"/Books & Literature/Children's Literature\": 0.9200000166893005,\n",
       "  \"/People & Society/Kids & Teens/Children's Interests\": 0.8500000238418579,\n",
       "  '/People & Society/Subcultures & Niche Interests': 0.5600000023841858},\n",
       " 'string3.txt': {'/Internet & Telecom/Mobile & Wireless': 0.6299999952316284,\n",
       "  '/Internet & Telecom/Service Providers': 0.5199999809265137},\n",
       " 'string2.txt': {'/Internet & Telecom': 0.7099999785423279}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index('/home/affine/GCP/NLP_Content_Classification/text_files','index.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "For each file in directory it is calling above classify function that passes the text files to the Cloud Natural Language API to be classified into content categories and gives categories of that file in output.\n",
    "\n",
    "\n",
    "The results from the Cloud Natural Language API for each file are organized into a single dictionary, serialized as a JSON string,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Query with category labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It process input query category labels to find similar text files.\n",
    "\n",
    "\n",
    "- Find files in a directory that are most similar to a query label passed by the user.\n",
    "\n",
    "\n",
    "- In this we use a category label as the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first splitting the categories into individual levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labels(categories):\n",
    "    \"\"\"The category labels are of the form \"/a/b/c\" up to three levels,\n",
    "    for example \"/Computers & Electronics/Software\", and these labels\n",
    "    are used as keys in the categories dictionary, whose values are\n",
    "    confidence scores.\n",
    "    The split_labels function splits the keys into individual levels\n",
    "    while duplicating the confidence score, which allows a natural\n",
    "    boost in how we calculate similarity when more levels are in common.\n",
    "    Example:\n",
    "    If we have\n",
    "    x = {\"/a/b/c\": 0.5}\n",
    "    y = {\"/a/b\": 0.5}\n",
    "    z = {\"/a\": 0.5}\n",
    "    Then x and y are considered more similar than y and z.\n",
    "    \"\"\"\n",
    "    _categories = {}\n",
    "    for name, confidence in six.iteritems(categories):\n",
    "        labels = [label for label in name.split('/') if label]\n",
    "        for label in labels:\n",
    "            _categories[label] = confidence\n",
    "    return _categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then finding similarity between text based on their resulting content classification by using numpy for vector calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(categories1, categories2):\n",
    "    \"\"\"Cosine similarity of the categories treated as sparse vectors.\"\"\"\n",
    "    categories1 = split_labels(categories1)\n",
    "    categories2 = split_labels(categories2)\n",
    "\n",
    "    norm1 = numpy.linalg.norm(list(categories1.values()))\n",
    "    norm2 = numpy.linalg.norm(list(categories2.values()))\n",
    "\n",
    "    # Return the smallest possible similarity if either categories is empty.\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute the cosine similarity.\n",
    "    dot = 0.0\n",
    "    for label, confidence in six.iteritems(categories1):\n",
    "        dot += confidence * categories2.get(label, 0.0)\n",
    "\n",
    "    return dot / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then finding the indexed files that are the most similar to the query label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_category(index_file, category_string, n_top=3):\n",
    "    \"\"\"Find the indexed files that are the most similar to\n",
    "    the query label.\n",
    "\n",
    "    The list of all available labels:\n",
    "    https://cloud.google.com/natural-language/docs/categories\n",
    "    \"\"\"\n",
    "\n",
    "    with io.open(index_file, 'r') as f:\n",
    "        index = json.load(f)\n",
    "    # Make the category_string into a dictionary so that it is\n",
    "    # of the same format as what we get by calling classify.\n",
    "    query_categories = {category_string: 1.0}\n",
    "\n",
    "    similarities = []\n",
    "    for filename, categories in six.iteritems(index):\n",
    "        similarities.append(\n",
    "            (filename, similarity(query_categories, categories)))\n",
    "\n",
    "    similarities = sorted(similarities, key=lambda p: p[1], reverse=True)\n",
    "\n",
    "    print('=' * 20)\n",
    "    print('Query: {}\\n'.format(category_string))\n",
    "    print('\\nMost similar {} indexed texts:'.format(n_top))\n",
    "    for filename, sim in similarities[:n_top]:\n",
    "        print('\\tFilename: {}'.format(filename))\n",
    "        print('\\tSimilarity: {}'.format(sim))\n",
    "        print('\\n')\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Query: /Books & Literature\n",
      "\n",
      "\n",
      "Most similar 3 indexed texts:\n",
      "\tFilename: string4.txt\n",
      "\tSimilarity: 0.48081945867711245\n",
      "\n",
      "\n",
      "\tFilename: string6.txt\n",
      "\tSimilarity: 0.4741386255611049\n",
      "\n",
      "\n",
      "\tFilename: string5.txt\n",
      "\tSimilarity: 0.4526781570345511\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('string4.txt', 0.48081945867711245),\n",
       " ('string6.txt', 0.4741386255611049),\n",
       " ('string5.txt', 0.4526781570345511),\n",
       " ('string1.txt', 0.0),\n",
       " ('string3.txt', 0.0),\n",
       " ('string2.txt', 0.0)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_category('/home/affine/GCP/NLP_Content_Classification/index.json','/Books & Literature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Query with text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It process input query text to find similar text files.\n",
    "\n",
    "\n",
    "- Classify files in a directory based on category of a query text\n",
    "\n",
    "\n",
    "- In this we query with text that may not be part of the indexed text. The below query function is similar to the query_category function, with the added step of making a classifyText request for the text input, and using the results to query the index file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the indexed files that are the most similar to the query text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(index_file, text, n_top=3):\n",
    "    \"\"\"Find the indexed files that are the most similar to\n",
    "    the query text.\n",
    "    \"\"\"\n",
    "\n",
    "    with io.open(index_file, 'r') as f:\n",
    "        index = json.load(f)\n",
    "\n",
    "    # Get the categories of the query text.\n",
    "    query_categories = classify(text, verbose=False)\n",
    "\n",
    "    similarities = []\n",
    "    for filename, categories in six.iteritems(index):\n",
    "        similarities.append(\n",
    "            (filename, similarity(query_categories, categories)))\n",
    "\n",
    "    similarities = sorted(similarities, key=lambda p: p[1], reverse=True)\n",
    "\n",
    "    print('=' * 20)\n",
    "    print('Query: {}\\n'.format(text))\n",
    "    for category, confidence in six.iteritems(query_categories):\n",
    "        print('\\tCategory: {}, confidence: {}'.format(category, confidence))\n",
    "    print('\\nMost similar {} indexed texts:'.format(n_top))\n",
    "    for filename, sim in similarities[:n_top]:\n",
    "        print('\\tFilename: {}'.format(filename))\n",
    "        print('\\tSimilarity: {}'.format(sim))\n",
    "        print('\\n')\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: \n",
      " categories {\n",
      "  name: \"/Health\"\n",
      "  confidence: 0.5899999737739563\n",
      "}\n",
      "categories {\n",
      "  name: \"/People & Society\"\n",
      "  confidence: 0.5299999713897705\n",
      "}\n",
      "\n",
      "====================\n",
      "Query: Healthy children learn better. People with adequate nutrition are more productive and can create opportunities to gradually break the cycles of poverty and hunger\n",
      "\n",
      "\tCategory: /Health, confidence: 0.5899999737739563\n",
      "\tCategory: /People & Society, confidence: 0.5299999713897705\n",
      "\n",
      "Most similar 3 indexed texts:\n",
      "\tFilename: string1.txt\n",
      "\tSimilarity: 0.472457802007375\n",
      "\n",
      "\n",
      "\tFilename: string5.txt\n",
      "\tSimilarity: 0.29639893032291637\n",
      "\n",
      "\n",
      "\tFilename: string4.txt\n",
      "\tSimilarity: 0.282897926749342\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('string1.txt', 0.472457802007375),\n",
       " ('string5.txt', 0.29639893032291637),\n",
       " ('string4.txt', 0.282897926749342),\n",
       " ('string6.txt', 0.19286617819127827),\n",
       " ('string3.txt', 0.0),\n",
       " ('string2.txt', 0.0)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query('/home/affine/GCP/NLP_Content_Classification/index.json',\"Healthy children learn better. People with adequate nutrition are more productive and can create opportunities to gradually break the cycles of poverty and hunger\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
